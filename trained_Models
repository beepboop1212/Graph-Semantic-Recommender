{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12919388,"sourceType":"datasetVersion","datasetId":8174796}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Semantic Engine work","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers faiss-cpu --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:00:23.491999Z","iopub.execute_input":"2025-08-31T08:00:23.492662Z","iopub.status.idle":"2025-08-31T08:01:44.409730Z","shell.execute_reply.started":"2025-08-31T08:00:23.492637Z","shell.execute_reply":"2025-08-31T08:01:44.409056Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\n\nprint(\"Libraries installed and imported.\")\n\n# --- IMPORTANT ---\n# Make sure this path points to your cleaned CSV file from the previous step.\n# If you saved it in /kaggle/working/, the path will be as below.\n# If you uploaded it as a new dataset, it might be /kaggle/input/your-dataset-name/articles_cleaned.csv\nARTICLES_CLEAN_PATH = '/kaggle/input/my-own/articles_cleaned.csv'\n\n# Load the data, ensuring article_id is a string\narticles_df = pd.read_csv(ARTICLES_CLEAN_PATH, dtype={'article_id': str})\n\nprint(f\"Loaded {len(articles_df)} articles from the cleaned dataset.\")\narticles_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:03:05.364470Z","iopub.execute_input":"2025-08-31T08:03:05.365043Z","iopub.status.idle":"2025-08-31T08:03:38.642122Z","shell.execute_reply.started":"2025-08-31T08:03:05.365014Z","shell.execute_reply":"2025-08-31T08:03:38.641210Z"}},"outputs":[{"name":"stderr","text":"2025-08-31 08:03:23.609811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756627403.823197      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756627403.886967      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Libraries installed and imported.\nLoaded 50431 articles from the cleaned dataset.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   article_id          prod_name product_type_name  product_group_name  \\\n0  0108775015          Strap top          Vest top  Garment Upper body   \n1  0108775044          Strap top          Vest top  Garment Upper body   \n2  0110065001  OP T-shirt (Idro)               Bra           Underwear   \n3  0110065002  OP T-shirt (Idro)               Bra           Underwear   \n4  0110065011  OP T-shirt (Idro)               Bra           Underwear   \n\n  graphical_appearance_name colour_group_name perceived_colour_value_name  \\\n0                     Solid             Black                        Dark   \n1                     Solid             White                       Light   \n2                     Solid             Black                        Dark   \n3                     Solid             White                       Light   \n4                     Solid       Light Beige                 Dusty Light   \n\n  perceived_colour_master_name department_name        index_name  \\\n0                        Black    Jersey Basic        Ladieswear   \n1                        White    Jersey Basic        Ladieswear   \n2                        Black  Clean Lingerie  Lingeries/Tights   \n3                        White  Clean Lingerie  Lingeries/Tights   \n4                        Beige  Clean Lingerie  Lingeries/Tights   \n\n  index_group_name            section_name garment_group_name  \\\n0       Ladieswear  Womens Everyday Basics       Jersey Basic   \n1       Ladieswear  Womens Everyday Basics       Jersey Basic   \n2       Ladieswear         Womens Lingerie  Under-, Nightwear   \n3       Ladieswear         Womens Lingerie  Under-, Nightwear   \n4       Ladieswear         Womens Lingerie  Under-, Nightwear   \n\n                                         detail_desc  \n0            Jersey top with narrow shoulder straps.  \n1            Jersey top with narrow shoulder straps.  \n2  Microfibre T-shirt bra with underwired, moulde...  \n3  Microfibre T-shirt bra with underwired, moulde...  \n4  Microfibre T-shirt bra with underwired, moulde...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>prod_name</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>graphical_appearance_name</th>\n      <th>colour_group_name</th>\n      <th>perceived_colour_value_name</th>\n      <th>perceived_colour_master_name</th>\n      <th>department_name</th>\n      <th>index_name</th>\n      <th>index_group_name</th>\n      <th>section_name</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0108775015</td>\n      <td>Strap top</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>Solid</td>\n      <td>Black</td>\n      <td>Dark</td>\n      <td>Black</td>\n      <td>Jersey Basic</td>\n      <td>Ladieswear</td>\n      <td>Ladieswear</td>\n      <td>Womens Everyday Basics</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0108775044</td>\n      <td>Strap top</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>Solid</td>\n      <td>White</td>\n      <td>Light</td>\n      <td>White</td>\n      <td>Jersey Basic</td>\n      <td>Ladieswear</td>\n      <td>Ladieswear</td>\n      <td>Womens Everyday Basics</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0110065001</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>Solid</td>\n      <td>Black</td>\n      <td>Dark</td>\n      <td>Black</td>\n      <td>Clean Lingerie</td>\n      <td>Lingeries/Tights</td>\n      <td>Ladieswear</td>\n      <td>Womens Lingerie</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0110065002</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>Solid</td>\n      <td>White</td>\n      <td>Light</td>\n      <td>White</td>\n      <td>Clean Lingerie</td>\n      <td>Lingeries/Tights</td>\n      <td>Ladieswear</td>\n      <td>Womens Lingerie</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0110065011</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>Solid</td>\n      <td>Light Beige</td>\n      <td>Dusty Light</td>\n      <td>Beige</td>\n      <td>Clean Lingerie</td>\n      <td>Lingeries/Tights</td>\n      <td>Ladieswear</td>\n      <td>Womens Lingerie</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# List of text columns to combine\ntext_feature_columns = [\n    'prod_name',\n    'product_type_name',\n    'product_group_name',\n    'graphical_appearance_name',\n    'colour_group_name',\n    'perceived_colour_value_name',\n    'perceived_colour_master_name',\n    'department_name',\n    'index_name',\n    'section_name',\n    'garment_group_name',\n    'detail_desc'\n]\n\n# --- Pre-processing: Fill any potential missing values in these columns ---\n# This is crucial to prevent errors during string concatenation.\nfor col in text_feature_columns:\n    articles_df[col].fillna('', inplace=True)\n\n# --- Create the combined text feature with clear separators ---\n# This structured format helps the model understand the context of each word.\ndef create_embedding_text(row):\n    return (\n        f\"Name: {row['prod_name']}. \"\n        f\"Type: {row['product_type_name']} in {row['product_group_name']}. \"\n        f\"Appearance: {row['graphical_appearance_name']} with color {row['colour_group_name']}. \"\n        f\"Category: {row['department_name']}, {row['section_name']}. \"\n        f\"Description: {row['detail_desc']}\"\n    )\n\narticles_df['text_for_embedding'] = articles_df.apply(create_embedding_text, axis=1)\n\nprint(\"--- Example of the new comprehensive text feature ---\")\nprint(articles_df[['article_id', 'text_for_embedding']].head().to_string())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:03:48.352287Z","iopub.execute_input":"2025-08-31T08:03:48.352566Z","iopub.status.idle":"2025-08-31T08:03:49.161466Z","shell.execute_reply.started":"2025-08-31T08:03:48.352547Z","shell.execute_reply":"2025-08-31T08:03:49.160653Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2615926203.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  articles_df[col].fillna('', inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"--- Example of the new comprehensive text feature ---\n   article_id                                                                                                                                                                                                                                                                                                                                                                                   text_for_embedding\n0  0108775015                                                                                                                                                                                                      Name: Strap top. Type: Vest top in Garment Upper body. Appearance: Solid with color Black. Category: Jersey Basic, Womens Everyday Basics. Description: Jersey top with narrow shoulder straps.\n1  0108775044                                                                                                                                                                                                      Name: Strap top. Type: Vest top in Garment Upper body. Appearance: Solid with color White. Category: Jersey Basic, Womens Everyday Basics. Description: Jersey top with narrow shoulder straps.\n2  0110065001        Name: OP T-shirt (Idro). Type: Bra in Underwear. Appearance: Solid with color Black. Category: Clean Lingerie, Womens Lingerie. Description: Microfibre T-shirt bra with underwired, moulded, lightly padded cups that shape the bust and provide good support. Narrow adjustable shoulder straps and a narrow hook-and-eye fastening at the back. Without visible seams for greater comfort.\n3  0110065002        Name: OP T-shirt (Idro). Type: Bra in Underwear. Appearance: Solid with color White. Category: Clean Lingerie, Womens Lingerie. Description: Microfibre T-shirt bra with underwired, moulded, lightly padded cups that shape the bust and provide good support. Narrow adjustable shoulder straps and a narrow hook-and-eye fastening at the back. Without visible seams for greater comfort.\n4  0110065011  Name: OP T-shirt (Idro). Type: Bra in Underwear. Appearance: Solid with color Light Beige. Category: Clean Lingerie, Womens Lingerie. Description: Microfibre T-shirt bra with underwired, moulded, lightly padded cups that shape the bust and provide good support. Narrow adjustable shoulder straps and a narrow hook-and-eye fastening at the back. Without visible seams for greater comfort.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load a pre-trained sentence transformer model\n# 'all-MiniLM-L6-v2' is a great balance of speed and performance.\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nprint(\"Generating semantic embeddings for all articles. This will take a few minutes...\")\n# Convert the text to embeddings\nsemantic_embeddings = model.encode(\n    articles_df['text_for_embedding'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True\n)\n\nprint(f\"\\nEmbeddings generated. Shape: {semantic_embeddings.shape}\")\n\n# --- Build the FAISS Index for fast searching ---\nembedding_dimension = semantic_embeddings.shape[1]\n# We use IndexFlatL2, which performs exact search using L2 (Euclidean) distance.\nindex = faiss.IndexFlatL2(embedding_dimension)\n\n# Add the article embeddings to the index. FAISS requires float32 data type.\nindex.add(semantic_embeddings.astype('float32'))\n\nprint(f\"FAISS index built. Total items in index: {index.ntotal}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:03:59.849969Z","iopub.execute_input":"2025-08-31T08:03:59.850279Z","iopub.status.idle":"2025-08-31T08:04:37.280292Z","shell.execute_reply.started":"2025-08-31T08:03:59.850250Z","shell.execute_reply":"2025-08-31T08:04:37.279504Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc611372efc44ac2a1a552f29a3e2ec8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2110065b42e143fd93c80aa93beb684c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d05407f0f3b41a5977dba6c8c5d74f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2949f5710b424ef89646d031f2d9b98b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb52de1229834861b70f61193d6fb188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8732562dc3934574a1a6acd086b85a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"688a9226da004e2089c72f8793c047b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fddfdb5e3974434692018dd41b407314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10fbea60cf34422897ab1f990e8faaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d9b1b35f9184059bf255931e3e879d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8975f3e39134643b88820fe6ac68da1"}},"metadata":{}},{"name":"stdout","text":"Generating semantic embeddings for all articles. This will take a few minutes...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1576 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c99337266c641b4afff87f5b1dfd9a8"}},"metadata":{}},{"name":"stdout","text":"\nEmbeddings generated. Shape: (50431, 384)\nFAISS index built. Total items in index: 50431\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Define paths for the output files\nFAISS_INDEX_PATH = '/kaggle/working/semantic_faiss_index.bin'\nARTICLE_IDS_MAP_PATH = '/kaggle/working/semantic_article_ids.csv'\n\n# Save the FAISS index to disk\nfaiss.write_index(index, FAISS_INDEX_PATH)\n\n# CRITICAL: Save the article_ids in the *exact same order* as the embeddings.\n# This file is our map from an index position (e.g., 42) back to the real article_id.\narticles_df[['article_id']].to_csv(ARTICLE_IDS_MAP_PATH, index=False)\n\nprint(f\"Successfully saved semantic engine artifacts to /kaggle/working/:\")\nprint(f\"- FAISS Index: {FAISS_INDEX_PATH}\")\nprint(f\"- Article ID Mapping: {ARTICLE_IDS_MAP_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:04:45.534336Z","iopub.execute_input":"2025-08-31T08:04:45.534587Z","iopub.status.idle":"2025-08-31T08:04:45.627573Z","shell.execute_reply.started":"2025-08-31T08:04:45.534570Z","shell.execute_reply":"2025-08-31T08:04:45.626932Z"}},"outputs":[{"name":"stdout","text":"Successfully saved semantic engine artifacts to /kaggle/working/:\n- FAISS Index: /kaggle/working/semantic_faiss_index.bin\n- Article ID Mapping: /kaggle/working/semantic_article_ids.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def search_products(query, k=5):\n    \"\"\"Encodes a query, searches the FAISS index, and returns top k results.\"\"\"\n    query_vector = model.encode([query], convert_to_numpy=True).astype('float32')\n    distances, indices = index.search(query_vector, k)\n    \n    print(f\"\\n--- Top {k} results for query: '{query}' ---\\n\")\n    \n    for rank, idx in enumerate(indices[0]):\n        # Directly get the row from articles_df using iloc\n        row = articles_df.iloc[idx]\n        article_id = row['article_id']\n        \n        print(f\"Result {rank+1}:\")\n        print(f\"  Article ID: {article_id}\")\n        print(f\"  Product Name: {row['prod_name']}\")\n        # --- ADDED THIS LINE ---\n        print(f\"  Color: {row['colour_group_name']}\")\n        # ---------------------\n        print(f\"  Description: {row['detail_desc']}\")\n        print(f\"  Similarity Score (L2 Distance): {distances[0][rank]:.4f}\\n\")\n\n# --- Test queries ---\n# Now, when you run this, the color will be included in the output.\nsearch_products(\"black dress for summer\")\nsearch_products(\"blue wide leg jeans\")\nsearch_products(\"white sneakers for men\")\nsearch_products(\"blue striped t shirt for men\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:17:31.289697Z","iopub.execute_input":"2025-08-31T08:17:31.290212Z","iopub.status.idle":"2025-08-31T08:17:31.399208Z","shell.execute_reply.started":"2025-08-31T08:17:31.290158Z","shell.execute_reply":"2025-08-31T08:17:31.398493Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae901abafa1e4c1ab62f7f14667c7a40"}},"metadata":{}},{"name":"stdout","text":"\n--- Top 5 results for query: 'black dress for summer' ---\n\nResult 1:\n  Article ID: 0926246001\n  Product Name: Summer nights dress\n  Color: Black\n  Description: Short lace dress with a concealed zip at the back and long, slightly wider sleeves with narrow, covered elastication at the cuffs. Fitted at the top, a seam at the waist and a wide, circular skirt. Lined.\n  Similarity Score (L2 Distance): 0.6982\n\nResult 2:\n  Article ID: 0926246003\n  Product Name: Summer nights dress\n  Color: Beige\n  Description: Short lace dress with a concealed zip at the back and long, slightly wider sleeves with narrow, covered elastication at the cuffs. Fitted at the top, a seam at the waist and a wide, circular skirt. Lined.\n  Similarity Score (L2 Distance): 0.7286\n\nResult 3:\n  Article ID: 0786242001\n  Product Name: HW Black swan\n  Color: Black\n  Description: Fancy dress costume with a lace body and a sewn-in flared skirt in tulle. Body with narrow adjustable shoulder straps, padded cups, a zip at the back and support panels at the front, back and sides. Lower section in glossy jersey and a skirt that ties with satin ribbons at the back.\n  Similarity Score (L2 Distance): 0.7640\n\nResult 4:\n  Article ID: 0496762004\n  Product Name: Summer strap dress\n  Color: Black\n  Description: Short dress in soft jersey with a V-neck, narrow, adjustable shoulder straps, seam at the waist and flared skirt.\n  Similarity Score (L2 Distance): 0.7647\n\nResult 5:\n  Article ID: 0496762005\n  Product Name: Summer strap dress\n  Color: Grey\n  Description: Short dress in soft jersey with a V-neck, narrow, adjustable shoulder straps, seam at the waist and flared skirt.\n  Similarity Score (L2 Distance): 0.7758\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f775105aec42038d43ee0527c56b3a"}},"metadata":{}},{"name":"stdout","text":"\n--- Top 5 results for query: 'blue wide leg jeans' ---\n\nResult 1:\n  Article ID: 0833622001\n  Product Name: WIDELEG LIGHT WEIGHT\n  Color: Light Blue\n  Description: Cropped jeans in washed, lightweight cotton denim with covered elastication at the waist and a fake fly. Wide, straight-cut legs with scalloped, hole embroidered hems.\n  Similarity Score (L2 Distance): 0.5924\n\nResult 2:\n  Article ID: 0926502001\n  Product Name: Hudson Wide Leg Denim\n  Color: Blue\n  Description: 5-pocket jeans in washed cotton denim with a high waist, zip fly and button and wide legs. The cotton content of the jeans is partly recycled.\n  Similarity Score (L2 Distance): 0.5968\n\nResult 3:\n  Article ID: 0725338002\n  Product Name: Empire HW wide leg denim\n  Color: Yellow\n  Description: 5-pocket jeans in dyed denim with a high waist, zip fly and button and straight, wide legs.\n  Similarity Score (L2 Distance): 0.6087\n\nResult 4:\n  Article ID: 0781135002\n  Product Name: Wide H.W Ankle\n  Color: Blue\n  Description: 5-pocket, ankle-length jeans in washed, stretch denim with a high waist and straight, wide legs. The cotton content of the jeans is partly recycled.\n  Similarity Score (L2 Distance): 0.6109\n\nResult 5:\n  Article ID: 0781135005\n  Product Name: Wide H.W Ankle\n  Color: Blue\n  Description: 5-pocket, ankle-length jeans in washed, stretch denim with a high waist and straight, wide legs. The cotton content of the jeans is partly recycled.\n  Similarity Score (L2 Distance): 0.6109\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8547720a286467f9bbee5119d85c40e"}},"metadata":{}},{"name":"stdout","text":"\n--- Top 5 results for query: 'white sneakers for men' ---\n\nResult 1:\n  Article ID: 0889712001\n  Product Name: Alton Sneaker\n  Color: White\n  Description: Trainers in imitation leather with a padded edge and tongue, and lacing at the front. Linings and insoles in jersey made from recycled polyester, and fluted soles.\n  Similarity Score (L2 Distance): 0.7355\n\nResult 2:\n  Article ID: 0728830001\n  Product Name: Beta Low court Sneaker\n  Color: White\n  Description: Trainers with a padded top edge and lacing at the front. Mesh linings and insoles and rubber soles.\n  Similarity Score (L2 Distance): 0.7416\n\nResult 3:\n  Article ID: 0766093002\n  Product Name: Rhino Sneaker\n  Color: White\n  Description: Trainers in imitation leather with a padded top edge and tongue, and lacing at the front. Mesh linings and insoles and patterned soles.\n  Similarity Score (L2 Distance): 0.7840\n\nResult 4:\n  Article ID: 0585138001\n  Product Name: Red high top sneaker\n  Color: Beige\n  Description: Hi-tops in canvas and mesh with a rubber print and plastic details. Padded edge and tongue, lacing at the front and a loop at the back. Mesh linings and insoles and rubber soles.\n  Similarity Score (L2 Distance): 0.7891\n\nResult 5:\n  Article ID: 0806711001\n  Product Name: Picasso Sneaker\n  Color: White\n  Description: Trainers in imitation leather with lacing at the front, a padded jersey tongue, shimmering metallic heel caps and a patent back section. Jersey linings and insoles and patterned soles.\n  Similarity Score (L2 Distance): 0.7926\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ddca271b49e469e8b2078c7d2c1bba5"}},"metadata":{}},{"name":"stdout","text":"\n--- Top 5 results for query: 'blue striped t shirt for men' ---\n\nResult 1:\n  Article ID: 0856395005\n  Product Name: ICE striped linen tee\n  Color: Dark Blue\n  Description: T-shirt in striped, airy linen jersey with a round neckline.\n  Similarity Score (L2 Distance): 0.7167\n\nResult 2:\n  Article ID: 0882817002\n  Product Name: Slice Tee\n  Color: Light Turquoise\n  Description: Short-sleeved sports top in fast-drying functional fabric with a reflective print. Slightly longer and rounded at the back.\n  Similarity Score (L2 Distance): 0.7236\n\nResult 3:\n  Article ID: 0882817001\n  Product Name: Slice Tee\n  Color: Grey\n  Description: Short-sleeved sports top in fast-drying functional fabric with a reflective print. Slightly longer and rounded at the back.\n  Similarity Score (L2 Distance): 0.7421\n\nResult 4:\n  Article ID: 0792899001\n  Product Name: GREY 50?s pocket tee\n  Color: Black\n  Description: T-shirt in stretch cotton jersey with raw edges, a chest pocket and short sleeves with sewn-in turn-ups.\n  Similarity Score (L2 Distance): 0.7507\n\nResult 5:\n  Article ID: 0856395003\n  Product Name: ICE striped linen tee\n  Color: Dark Green\n  Description: T-shirt in striped, airy linen jersey with a round neckline.\n  Similarity Score (L2 Distance): 0.7584\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**Block to run while demonstration**","metadata":{}},{"cell_type":"code","source":"# === STEP 1: Import Libraries and Set Up Paths ===\nimport pandas as pd\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\n\n# Define the paths to the artifacts we saved earlier\nFAISS_INDEX_PATH = '/kaggle/working/semantic_faiss_index.bin'\nARTICLE_IDS_MAP_PATH = '/kaggle/working/semantic_article_ids.csv'\nARTICLES_DATA_PATH = '/kaggle/input/my-own/articles_cleaned.csv' # Needed for displaying product details\n\nprint(\"--- Loading necessary files ---\")\n\n# === STEP 2: Load the Artifacts into Memory ===\n\n# Load the FAISS index\ntry:\n    index = faiss.read_index(FAISS_INDEX_PATH)\n    print(f\"✓ FAISS index loaded successfully. Contains {index.ntotal} vectors.\")\nexcept Exception as e:\n    print(f\"✗ Error loading FAISS index: {e}\")\n\n# Load the article ID mapping file\ntry:\n    article_id_map_df = pd.read_csv(ARTICLE_IDS_MAP_PATH, dtype={'article_id': str})\n    print(f\"✓ Article ID map loaded successfully. Contains {len(article_id_map_df)} IDs.\")\nexcept Exception as e:\n    print(f\"✗ Error loading article ID map: {e}\")\n\n# Load the full articles dataframe to get product details for display\ntry:\n    articles_df = pd.read_csv(ARTICLES_DATA_PATH, dtype={'article_id': str})\n    # Set article_id as the index for fast lookups (df.loc[...])\n    articles_df.set_index('article_id', inplace=True)\n    print(f\"✓ Full articles data loaded successfully.\")\nexcept Exception as e:\n    print(f\"✗ Error loading articles data: {e}\")\n\n# Load the pre-trained Sentence Transformer model\n# This must be the *exact same model* used to create the embeddings\ntry:\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    print(\"✓ Sentence Transformer model loaded successfully.\")\nexcept Exception as e:\n    print(f\"✗ Error loading Sentence Transformer model: {e}\")\n\nprint(\"\\n--- Semantic Search Engine is Ready ---\")\n\n\n# === STEP 3: Define the Reusable Search Function ===\n\ndef semantic_search(query: str, top_k: int = 5):\n    \"\"\"\n    Takes a text query, embeds it, searches the FAISS index,\n    and prints the details of the top_k most similar products.\n    \"\"\"\n    if 'index' not in globals() or 'model' not in globals():\n        print(\"Error: Search index or model not loaded.\")\n        return\n\n    print(f\"\\n=================================================\")\n    print(f\"| Searching for: '{query}' (Top {top_k} Results) |\")\n    print(f\"=================================================\")\n\n    # 1. Embed the query\n    query_vector = model.encode([query], convert_to_numpy=True).astype('float32')\n    \n    # 2. Search the FAISS index\n    distances, indices = index.search(query_vector, top_k)\n    \n    # 3. Retrieve and display the results\n    for i, idx in enumerate(indices[0]):\n        # Get the article_id from our mapping dataframe\n        article_id = article_id_map_df.iloc[idx]['article_id']\n        \n        try:\n            # Get the product details from the main articles dataframe using .loc for speed\n            product_details = articles_df.loc[article_id]\n            \n            print(f\"\\n--- Result #{i+1} ---\")\n            print(f\"  Article ID: {article_id}\")\n            print(f\"  Product Name: {product_details['prod_name']}\")\n            print(f\"  Color: {product_details['colour_group_name']}\")\n            print(f\"  Description: {product_details['detail_desc']}\")\n            print(f\"  L2 Distance (Similarity): {distances[0][i]:.4f}\") # Lower is better\n        except KeyError:\n            print(f\"\\n--- Result #{i+1} ---\")\n            print(f\"  Could not find details for article_id: {article_id}\")\n\n# === STEP 4: Demonstrate with Example Queries ===\n# You can add or change any of these queries to demonstrate the engine's power.\n\nsemantic_search(\"red floral summer dress\")\nsemantic_search(\"men's dark wash slim fit jeans\")\nsemantic_search(\"pink hoodie with a zipper\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:29:25.401819Z","iopub.execute_input":"2025-08-31T08:29:25.402376Z","iopub.status.idle":"2025-08-31T08:29:27.417825Z","shell.execute_reply.started":"2025-08-31T08:29:25.402355Z","shell.execute_reply":"2025-08-31T08:29:27.417299Z"}},"outputs":[{"name":"stdout","text":"--- Loading necessary files ---\n✓ FAISS index loaded successfully. Contains 50431 vectors.\n✓ Article ID map loaded successfully. Contains 50431 IDs.\n✓ Full articles data loaded successfully.\n✓ Sentence Transformer model loaded successfully.\n\n--- Semantic Search Engine is Ready ---\n\n=================================================\n| Searching for: 'red floral summer dress' (Top 5 Results) |\n=================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6c3f375be345c4a09694d63a9fbb96"}},"metadata":{}},{"name":"stdout","text":"\n--- Result #1 ---\n  Article ID: 0733076002\n  Product Name: Red Velvet\n  Color: Light Pink\n  Description: Sleeveless, ankle-length dress in a viscose crêpe weave with a V-neck, covered buttons down the front, a gathered seam at the waist and a straight-cut skirt that flares gently to the hem. Unlined.\n  L2 Distance (Similarity): 0.6747\n\n--- Result #2 ---\n  Article ID: 0733076004\n  Product Name: Red Velvet\n  Color: Dark Blue\n  Description: Sleeveless, ankle-length dress in a viscose crêpe weave with a V-neck, covered buttons down the front, a gathered seam at the waist and a straight-cut skirt that flares gently to the hem. Unlined.\n  L2 Distance (Similarity): 0.6813\n\n--- Result #3 ---\n  Article ID: 0733076001\n  Product Name: Red Velvet\n  Color: Off White\n  Description: Sleeveless, ankle-length dress in a viscose crêpe weave with a V-neck, covered buttons down the front, a gathered seam at the waist and a straight-cut skirt that flares gently to the hem. Unlined.\n  L2 Distance (Similarity): 0.6866\n\n--- Result #4 ---\n  Article ID: 0892278001\n  Product Name: Rose dress\n  Color: White\n  Description: Short-sleeved dress in patterned, crinkled jersey with an opening and button at the back of the neck. Seam at the waist and a shimmering skirt in layers of tulle to create volume. Lined skirt.\n  L2 Distance (Similarity): 0.8352\n\n--- Result #5 ---\n  Article ID: 0854883004\n  Product Name: Rosa dress\n  Color: Red\n  Description: Maxi dress in softly draping viscose jersey with narrow, tie-top shoulder straps. Unlined.\n  L2 Distance (Similarity): 0.8458\n\n=================================================\n| Searching for: 'men's dark wash slim fit jeans' (Top 5 Results) |\n=================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eeb2b17bd7a4cb4b33d5373bbfb7a76"}},"metadata":{}},{"name":"stdout","text":"\n--- Result #1 ---\n  Article ID: 0891638003\n  Product Name: Regular fit Lowprice\n  Color: Dark Grey\n  Description: 5-pocket jeans in washed, stretch denim with a regular waist, zip fly and button and gently tapered legs with good room for movement over the thighs and knees.\n  L2 Distance (Similarity): 0.5930\n\n--- Result #2 ---\n  Article ID: 0891638002\n  Product Name: Regular fit Lowprice\n  Color: Dark Blue\n  Description: 5-pocket jeans in washed, stretch denim with a regular waist, zip fly and button and gently tapered legs with good room for movement over the thighs and knees.\n  L2 Distance (Similarity): 0.5953\n\n--- Result #3 ---\n  Article ID: 0753512001\n  Product Name: Skinny Midprice No Fade Black\n  Color: Black\n  Description: 5-pocket jeans in stretch organic cotton denim that has been dyed multiple times for a better post-wash colour. Regular waist, zip fly and skinny legs.\n  L2 Distance (Similarity): 0.6033\n\n--- Result #4 ---\n  Article ID: 0754044001\n  Product Name: Athletic Skinny Fit\n  Color: Blue\n  Description: 5-pocket jeans in washed, stretch denim with a regular waist, zip fly and button and skinny legs. The cotton content of the jeans is partly recycled.\n  L2 Distance (Similarity): 0.6093\n\n--- Result #5 ---\n  Article ID: 0891638004\n  Product Name: Regular fit Lowprice\n  Color: Blue\n  Description: 5-pocket jeans in washed, stretch denim with a regular waist, zip fly and button and gently tapered legs with good room for movement over the thighs and knees.\n  L2 Distance (Similarity): 0.6148\n\n=================================================\n| Searching for: 'pink hoodie with a zipper' (Top 5 Results) |\n=================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cd5bf84237640dbb0ce61889aebb09d"}},"metadata":{}},{"name":"stdout","text":"\n--- Result #1 ---\n  Article ID: 0907692001\n  Product Name: Eclipse zip hood(1)\n  Color: Black\n  Description: Oversized zip-through hoodie in sweatshirt fabric with a lined, drawstring hood and zip down the front. Dropped shoulders, long sleeves and ribbing at the cuffs and hem. The polyester content of the hoodie is partly recycled.\n  L2 Distance (Similarity): 0.6135\n\n--- Result #2 ---\n  Article ID: 0557246012\n  Product Name: Hood W Zip\n  Color: Dark Red\n  Description: Long-sleeved jacket in sweatshirt fabric with a lined drawstring hood, zip down the front, side pockets and ribbing at the cuffs and hem. Soft brushed inside.\n  L2 Distance (Similarity): 0.6637\n\n--- Result #3 ---\n  Article ID: 0762930001\n  Product Name: Glazing zip hoodie\n  Color: Dark Pink\n  Description: Jacket in soft, marled sweatshirt fabric with a double-layered drawstring hood, and a zip down the front and at the sides. Long raglan sleeves and ribbing at the cuffs and hem. Soft brushed inside.\n  L2 Distance (Similarity): 0.6823\n\n--- Result #4 ---\n  Article ID: 0800342011\n  Product Name: HAPPY half zip\n  Color: Light Pink\n  Description: Block-coloured top in sweatshirt fabric made from an organic cotton blend with a ribbed stand-up collar, zip at the top, long sleeves with ribbed cuffs, and covered elastication at the hem. Soft brushed inside.\n  L2 Distance (Similarity): 0.6835\n\n--- Result #5 ---\n  Article ID: 0800342013\n  Product Name: HAPPY half zip\n  Color: Pink\n  Description: Block-coloured top in sweatshirt fabric made from an organic cotton blend with a ribbed stand-up collar, zip at the top, long sleeves with ribbed cuffs, and covered elastication at the hem. Soft brushed inside.\n  L2 Distance (Similarity): 0.6845\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Model draft","metadata":{}},{"cell_type":"code","source":"# Install PyTorch Geometric with correct wheels\n!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n!pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:00:30.134938Z","iopub.execute_input":"2025-09-02T06:00:30.135651Z","iopub.status.idle":"2025-09-02T06:00:53.058945Z","shell.execute_reply.started":"2025-09-02T06:00:30.135619Z","shell.execute_reply":"2025-09-02T06:00:53.058227Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.2+pt26cu124\nLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.18+pt26cu124\nLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.3)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2024.2.0)\nInstalling collected packages: torch-cluster\nSuccessfully installed torch-cluster-1.6.3+pt26cu124\nLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch-spline-conv\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-spline-conv\nSuccessfully installed torch-spline-conv-1.2.2+pt26cu124\nLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting pyg-lib\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyg-lib\nSuccessfully installed pyg-lib-0.4.0+pt26cu124\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.13)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.5.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Load the data\narticles_df = pd.read_csv('/kaggle/input/my-own/articles_cleaned.csv')\ncustomers_df = pd.read_csv('/kaggle/input/my-own/customers_cleaned.csv')\ntransactions_df = pd.read_csv('/kaggle/input/my-own/transactions_cleaned.csv')\n\n# For development on Kaggle, it's wise to start with a smaller sample\n# Let's take transactions from the last N weeks to keep the graph manageable\ntransactions_df['t_dat'] = pd.to_datetime(transactions_df['t_dat'])\nlatest_date = transactions_df['t_dat'].max()\ntransactions_sample = transactions_df[transactions_df['t_dat'] > latest_date - pd.to_timedelta('14 days')]\n\n# Filter customers and articles to only those present in the sample\nactive_articles = transactions_sample['article_id'].unique()\nactive_customers = transactions_sample['customer_id'].unique()\n\narticles_df = articles_df[articles_df['article_id'].isin(active_articles)]\ncustomers_df = customers_df[customers_df['customer_id'].isin(active_customers)]\n\nprint(f\"Sampled Transactions: {len(transactions_sample)}\")\nprint(f\"Active Articles: {len(articles_df)}\")\nprint(f\"Active Customers: {len(customers_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:01:28.019660Z","iopub.execute_input":"2025-09-02T06:01:28.020358Z","iopub.status.idle":"2025-09-02T06:01:48.168282Z","shell.execute_reply.started":"2025-09-02T06:01:28.020327Z","shell.execute_reply":"2025-09-02T06:01:48.167517Z"}},"outputs":[{"name":"stdout","text":"Sampled Transactions: 480993\nActive Articles: 22208\nActive Customers: 127034\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom torch_geometric.data import HeteroData\n\ndata = HeteroData()\n\n# 1. Create Mappings for all node types to unique integer indices\n# This is crucial because GNNs work with integer indices.\n\ncustomer_mapping = {id: i for i, id in enumerate(customers_df['customer_id'].unique())}\narticle_mapping = {id: i for i, id in enumerate(articles_df['article_id'].unique())}\n# ... and so on for all your attribute types\nprod_group_mapping = {name: i for i, name in enumerate(articles_df['product_group_name'].unique())}\ncolour_group_mapping = {name: i for i, name in enumerate(articles_df['colour_group_name'].unique())}\n\n\n# 2. Define Node Features (optional but recommended)\n# For simplicity, we can start with learnable embeddings for each node.\n# The size `embedding_dim` is a hyperparameter you choose.\nembedding_dim = 64\ndata['customer'].x = torch.randn(len(customer_mapping), embedding_dim)\ndata['article'].x = torch.randn(len(article_mapping), embedding_dim)\ndata['product_group'].x = torch.randn(len(prod_group_mapping), embedding_dim)\ndata['colour_group'].x = torch.randn(len(colour_group_mapping), embedding_dim)\n\n# 3. Create Edge Index Tensors for each relationship type\n\n# Customer -> BOUGHT -> Article\ncust_src = [customer_mapping[id] for id in transactions_sample['customer_id']]\nart_dst = [article_mapping[id] for id in transactions_sample['article_id']]\ndata['customer', 'bought', 'article'].edge_index = torch.tensor([cust_src, art_dst])\n\n# Article -> BELONGS_TO -> ProductGroup\nart_src = [article_mapping[id] for id in articles_df['article_id']]\npg_dst = [prod_group_mapping[name] for name in articles_df['product_group_name']]\ndata['article', 'belongs_to', 'product_group'].edge_index = torch.tensor([art_src, pg_dst])\n\n# Article -> HAS_COLOUR -> ColourGroup\nart_src_color = [article_mapping[id] for id in articles_df['article_id']]\ncg_dst = [colour_group_mapping[name] for name in articles_df['colour_group_name']]\ndata['article', 'has_colour', 'colour_group'].edge_index = torch.tensor([art_src_color, cg_dst])\n\n# We also need the reverse edges for message passing in both directions\nfrom torch_geometric.transforms import ToUndirected\n\n# This creates reverse edges for all types, e.g., ('article', 'rev_bought', 'customer')\n# It's a common practice to make the graph undirected for message passing.\ndata = ToUndirected()(data)\n\nprint(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:02:29.853129Z","iopub.execute_input":"2025-09-02T06:02:29.853748Z","iopub.status.idle":"2025-09-02T06:02:42.829341Z","shell.execute_reply.started":"2025-09-02T06:02:29.853723Z","shell.execute_reply":"2025-09-02T06:02:42.828591Z"}},"outputs":[{"name":"stdout","text":"HeteroData(\n  customer={ x=[127034, 64] },\n  article={ x=[22208, 64] },\n  product_group={ x=[8, 64] },\n  colour_group={ x=[48, 64] },\n  (customer, bought, article)={ edge_index=[2, 480993] },\n  (article, belongs_to, product_group)={ edge_index=[2, 22208] },\n  (article, has_colour, colour_group)={ edge_index=[2, 22208] },\n  (article, rev_bought, customer)={ edge_index=[2, 480993] },\n  (product_group, rev_belongs_to, article)={ edge_index=[2, 22208] },\n  (colour_group, rev_has_colour, article)={ edge_index=[2, 22208] }\n)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch_geometric.nn import SAGEConv, HeteroConv, to_hetero\n\nclass HeteroGNN(nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.conv1 = HeteroConv({\n            # Define a SAGEConv for each edge type you want to learn from\n            ('customer', 'bought', 'article'): SAGEConv((-1, -1), hidden_channels),\n            ('article', 'belongs_to', 'product_group'): SAGEConv((-1, -1), hidden_channels),\n            ('article', 'has_colour', 'colour_group'): SAGEConv((-1, -1), hidden_channels),\n            \n            # Reverse edges\n            ('article', 'rev_bought', 'customer'): SAGEConv((-1, -1), hidden_channels),\n            ('product_group', 'rev_belongs_to', 'article'): SAGEConv((-1, -1), hidden_channels),\n            ('colour_group', 'rev_has_colour', 'article'): SAGEConv((-1, -1), hidden_channels),\n        }, aggr='sum')\n\n        self.conv2 = HeteroConv({\n            ('customer', 'bought', 'article'): SAGEConv((-1, -1), hidden_channels),\n            ('article', 'belongs_to', 'product_group'): SAGEConv((-1, -1), hidden_channels),\n            ('article', 'has_colour', 'colour_group'): SAGEConv((-1, -1), hidden_channels),\n            \n            ('article', 'rev_bought', 'customer'): SAGEConv((-1, -1), hidden_channels),\n            ('product_group', 'rev_belongs_to', 'article'): SAGEConv((-1, -1), hidden_channels),\n            ('colour_group', 'rev_has_colour', 'article'): SAGEConv((-1, -1), hidden_channels),\n        }, aggr='sum')\n\n    def forward(self, x_dict, edge_index_dict):\n        x_dict = self.conv1(x_dict, edge_index_dict)\n        x_dict = {key: x.relu() for key, x in x_dict.items()}\n        x_dict = self.conv2(x_dict, edge_index_dict)\n        return x_dict\n\n# Instantiate the model\nmodel = HeteroGNN(hidden_channels=64)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:02:46.187111Z","iopub.execute_input":"2025-09-02T06:02:46.187835Z","iopub.status.idle":"2025-09-02T06:02:46.245801Z","shell.execute_reply.started":"2025-09-02T06:02:46.187810Z","shell.execute_reply":"2025-09-02T06:02:46.245080Z"}},"outputs":[{"name":"stdout","text":"HeteroGNN(\n  (conv1): HeteroConv(num_relations=6)\n  (conv2): HeteroConv(num_relations=6)\n)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom torch_geometric.loader import LinkNeighborLoader\nimport torch.nn.functional as F\n\n# Select device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using device:\", device)\n\n# Move model to device\nmodel = model.to(device)\n\n# 1. Create a loader for mini-batch training on the links we want to predict\nedge_label_index = data['customer', 'bought', 'article'].edge_index\nloader = LinkNeighborLoader(\n    data,\n    num_neighbors=[10, 5],  # Sample 10 neighbors for the first layer, 5 for the second\n    edge_label_index=(('customer', 'article'), edge_label_index),\n    batch_size=128,\n    shuffle=True,\n    neg_sampling_ratio=1.0 # For each positive edge, sample 1 negative one\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\n# Training Loop\ndef train():\n    model.train()\n    total_loss = 0\n    for batch in loader:\n        batch = batch.to(device)  # Move batch to device\n\n        optimizer.zero_grad()\n        \n        # Get embeddings for the nodes in the current mini-batch\n        out = model(batch.x_dict, batch.edge_index_dict)\n        \n        # Get embeddings for the source and destination nodes of the links\n        src_emb = out['customer'][batch['customer', 'article'].edge_label_index[0]]\n        dst_emb = out['article'][batch['customer', 'article'].edge_label_index[1]]\n        \n        # Predict the link probability\n        pred = (src_emb * dst_emb).sum(dim=-1)\n        \n        loss = F.binary_cross_entropy_with_logits(\n            pred, batch['customer', 'article'].edge_label.float()\n        )\n        loss.backward()\n        optimizer.step()\n        total_loss += float(loss) * pred.numel()\n        \n    return total_loss / len(loader.dataset)\n\nfor epoch in range(1, 11):\n    loss = train()\n    print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:02:49.676957Z","iopub.execute_input":"2025-09-02T06:02:49.677382Z","iopub.status.idle":"2025-09-02T06:10:46.016014Z","shell.execute_reply.started":"2025-09-02T06:02:49.677351Z","shell.execute_reply":"2025-09-02T06:10:46.015270Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch: 001, Loss: 0.8191\nEpoch: 002, Loss: 0.3972\nEpoch: 003, Loss: 0.3099\nEpoch: 004, Loss: 0.2692\nEpoch: 005, Loss: 0.2467\nEpoch: 006, Loss: 0.2312\nEpoch: 007, Loss: 0.2188\nEpoch: 008, Loss: 0.2120\nEpoch: 009, Loss: 0.2047\nEpoch: 010, Loss: 0.1996\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport json\n\n# 1. Define the device you are using (best practice)\n# This will automatically use the GPU if available, otherwise fall back to CPU.\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# 2. Make sure your model is on the correct device and in evaluation mode\nmodel.to(device)\nmodel.eval()\n\n# 3. <<--- THIS IS THE FIX --- >>\n# Move the entire graph data object to the same device as the model.\n# PyG's .to() method conveniently moves all tensor attributes.\ndata = data.to(device)\n\n# 4. Now, perform inference. All tensors are on the same device.\nwith torch.no_grad():\n    final_embeddings = model(data.x_dict, data.edge_index_dict)\n\n# The 'final_embeddings' dictionary now contains tensors that are on the GPU.\n\n# 5. Save the embeddings and mappings\n# IMPORTANT: NumPy cannot access GPU memory. You must move the tensors\n# back to the CPU with .cpu() before converting them to NumPy arrays.\n\ncustomer_embeddings = final_embeddings['customer']\narticle_embeddings = final_embeddings['article']\n\n# Saving embeddings\nnp.save('customer_embeddings.npy', customer_embeddings.cpu().numpy())\nnp.save('article_embeddings.npy', article_embeddings.cpu().numpy())\nprint(\"Embeddings saved as .npy files.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:11:05.502933Z","iopub.execute_input":"2025-09-02T06:11:05.503674Z","iopub.status.idle":"2025-09-02T06:11:05.597914Z","shell.execute_reply.started":"2025-09-02T06:11:05.503647Z","shell.execute_reply":"2025-09-02T06:11:05.597295Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEmbeddings saved as .npy files.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"if all(isinstance(k, np.integer) for k in customer_mapping.keys()):\n    customer_mapping__serializable = {int(k): v for k, v in customer_mapping.items()}\n    print(\"Converted customer_mapping keys to standard int.\")\nelse:\n    customer_mapping_serializable = customer_mapping\n\n\n# FIX FOR article_mapping\n# The keys are numpy.int64, so we convert them to standard python int.\narticle_mapping_serializable = {int(k): v for k, v in article_mapping.items()}\nprint(\"Converted article_mapping keys to standard int.\")\n\n\n# Now save the converted dictionaries\nwith open('customer_mapping.json', 'w') as f:\n    json.dump(customer_mapping_serializable, f)\n\nwith open('article_mapping.json', 'w') as f:\n    json.dump(article_mapping_serializable, f)\n\nprint(\"Mappings saved as .json files.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:12:37.603207Z","iopub.execute_input":"2025-09-02T06:12:37.603772Z","iopub.status.idle":"2025-09-02T06:12:37.760527Z","shell.execute_reply.started":"2025-09-02T06:12:37.603743Z","shell.execute_reply":"2025-09-02T06:12:37.759923Z"}},"outputs":[{"name":"stdout","text":"Converted article_mapping keys to standard int.\nMappings saved as .json files.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --- In a new Kaggle session, you would load them like this ---\n# loaded_customer_embeddings = np.load('customer_embeddings.npy')\n# loaded_article_embeddings = np.load('article_embeddings.npy')\n\n# with open('customer_mapping.json', 'r') as f:\n#     loaded_customer_mapping = json.load(f)\n\n# with open('article_mapping.json', 'r') as f:\n#     loaded_article_mapping = json.load(f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# GNN Recommendation\ndef get_gnn_recommendations(customer_id, k=10):\n    customer_idx = customer_mapping[customer_id]\n    customer_emb = customer_embeddings[customer_idx]\n    \n    # Calculate cosine similarity between the user and all articles\n    scores = torch.matmul(article_embeddings, customer_emb)\n    \n    # Get top k scores\n    top_k_scores, top_k_indices = torch.topk(scores, k)\n    \n    # Convert article indices back to original IDs\n    rev_article_mapping = {v: k for k, v in article_mapping.items()}\n    recs = [rev_article_mapping[idx.item()] for idx in top_k_indices]\n    \n    return recs\n\nprint(\"GNN Recommendations for a sample customer:\", get_gnn_recommendations(list(customer_mapping.keys())[0]))\n\n\n# Baseline: Neighborhood Similarity (\"Customers who bought this also bought...\")\ndef get_baseline_recommendations(article_id, k=10):\n    # Find customers who bought the target article\n    customers_who_bought = transactions_df[transactions_df['article_id'] == article_id]['customer_id'].unique()\n    \n    # Find all other articles those customers bought\n    other_articles = transactions_df[transactions_df['customer_id'].isin(customers_who_bought)]['article_id']\n    \n    # Exclude the original article and count frequencies\n    recommendations = other_articles[other_articles != article_id].value_counts().nlargest(k).index.tolist()\n    \n    return recommendations\n\nprint(\"\\nBaseline Recommendations for a sample article:\", get_baseline_recommendations(list(article_mapping.keys())[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:12:59.812759Z","iopub.execute_input":"2025-09-02T06:12:59.813068Z","iopub.status.idle":"2025-09-02T06:13:00.217643Z","shell.execute_reply.started":"2025-09-02T06:12:59.813046Z","shell.execute_reply":"2025-09-02T06:13:00.216993Z"}},"outputs":[{"name":"stdout","text":"GNN Recommendations for a sample customer: [794321007, 911870003, 874122024, 816832011, 903276002, 863595004, 685813042, 562613010, 851094007, 928461001]\n\nBaseline Recommendations for a sample article: [767834002, 841383003, 783346001, 841383002, 565379002, 736870001, 749699002, 892910002, 610776001, 610776074]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Block to run while demonstration**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport torch\nimport torch.nn.functional as F\nfrom IPython.display import display, HTML\n\nprint(\"--- Loading all necessary assets for demonstration ---\")\n\n# --- 1. Load DataFrames ---\narticles_df = pd.read_csv('/kaggle/input/my-own/articles_cleaned.csv')\ntransactions_df = pd.read_csv('/kaggle/input/my-own/transactions_cleaned.csv')\n\n# --- 2. Load Embeddings and Mappings ---\n# Load embeddings and convert them to PyTorch tensors for calculations\ncustomer_embeddings = torch.from_numpy(np.load('/kaggle/working/customer_embeddings.npy'))\narticle_embeddings = torch.from_numpy(np.load('/kaggle/working/article_embeddings.npy'))\n\n# Load mappings\nwith open('/kaggle/working/customer_mapping.json', 'r') as f:\n    customer_mapping = json.load(f)\n\nwith open('/kaggle/working/article_mapping.json', 'r') as f:\n    # JSON saves integer keys as strings, so we must convert them back\n    article_mapping = {int(k): v for k, v in json.load(f).items()}\n\n# Create reverse mappings to go from index -> original ID\nidx_to_customer = {v: k for k, v in customer_mapping.items()}\nidx_to_article = {v: k for k, v in article_mapping.items()}\n\nprint(\"Assets loaded successfully.\\n\")\n\n\n# --- 3. Define Helper and Recommendation Functions ---\n\ndef display_customer_history(customer_id, num_items=5):\n    \"\"\"Looks up and displays the most recent purchases for a given customer with extended details.\"\"\"\n    display(HTML(f\"<h3>Purchase History for Customer: <code>{customer_id}</code></h3>\"))\n    \n    purchases = transactions_df[transactions_df['customer_id'] == customer_id]\n    \n    if purchases.empty:\n        print(\"No purchase history found for this customer.\")\n        return\n        \n    purchase_details = articles_df.merge(\n        purchases,\n        on='article_id'\n    ).sort_values(by='t_dat', ascending=False).head(num_items)\n    \n    # Define a comprehensive list of columns to display\n    display_cols = [\n        'prod_name',\n        'product_type_name',\n        'product_group_name',\n        'colour_group_name',\n        'department_name',\n        'section_name',\n        'garment_group_name',\n        'detail_desc'\n    ]\n    \n    # Ensure all columns exist before trying to display them\n    existing_cols = [col for col in display_cols if col in purchase_details.columns]\n    \n    print(\"Recent purchases:\")\n    display(purchase_details[existing_cols])\n\n\ndef get_gnn_recommendations(customer_id, k=10):\n    \"\"\"\n    Generates top-k GNN-based recommendations for a customer with extended details.\n    Filters out items they have already purchased.\n    \"\"\"\n    display(HTML(f\"<h3>Top {k} GNN Recommendations for Customer: <code>{customer_id}</code></h3>\"))\n\n    if customer_id not in customer_mapping:\n        print(\"Customer not found in the mapping.\")\n        return None\n\n    # 1. Get the user's embedding\n    customer_idx = customer_mapping[customer_id]\n    user_embedding = customer_embeddings[customer_idx].unsqueeze(0)\n\n    # 2. Calculate cosine similarity\n    scores = F.cosine_similarity(user_embedding, article_embeddings)\n\n    # 3. Filter out items the user has already bought\n    purchased_article_ids = transactions_df[transactions_df['customer_id'] == customer_id]['article_id'].unique()\n    purchased_indices = [article_mapping[aid] for aid in purchased_article_ids if aid in article_mapping]\n    \n    if purchased_indices:\n        scores[purchased_indices] = -1.0\n\n    # 4. Get top-k recommendations\n    top_k_scores, top_k_indices = torch.topk(scores, k)\n    \n    # 5. Convert indices back to original article IDs\n    recommended_article_ids = [idx_to_article[idx.item()] for idx in top_k_indices]\n    \n    # 6. Look up details and return a nice DataFrame\n    rec_details = articles_df[articles_df['article_id'].isin(recommended_article_ids)].copy()\n    rec_details['similarity_score'] = [round(s.item(), 4) for s in top_k_scores]\n    \n    rec_details = rec_details.set_index('article_id').loc[recommended_article_ids].reset_index()\n    \n    # Define the comprehensive list of columns to display for recommendations\n    display_cols = [\n        'prod_name',\n        'product_type_name',\n        'product_group_name',\n        'colour_group_name',\n        'perceived_colour_master_name',\n        'department_name',\n        'section_name',\n        'garment_group_name',\n        'detail_desc',\n        'similarity_score'\n    ]\n    \n    existing_cols = [col for col in display_cols if col in rec_details.columns]\n    \n    print(\"Recommended items:\")\n    display(rec_details[existing_cols])\n    return rec_details\n\n\n# --- 4. RUN THE DEMONSTRATION ---\n\n# You can change the index to see recommendations for different users\n# For example, try [10], [100], [500], etc.\ncustomer_index_to_show = 150\nsample_customer_id = list(customer_mapping.keys())[customer_index_to_show] \n\n# Show their purchase history for context\ndisplay_customer_history(sample_customer_id, num_items=5)\n\n# Generate and show new recommendations for them\nrecommendations = get_gnn_recommendations(sample_customer_id, k=7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T06:30:39.630736Z","iopub.execute_input":"2025-09-02T06:30:39.631501Z","iopub.status.idle":"2025-09-02T06:30:49.419671Z","shell.execute_reply.started":"2025-09-02T06:30:39.631472Z","shell.execute_reply":"2025-09-02T06:30:49.419050Z"}},"outputs":[{"name":"stdout","text":"--- Loading all necessary assets for demonstration ---\nAssets loaded successfully.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Purchase History for Customer: <code>005ab9cb5f4cfda446299f48d109c002cb5396a6646445d22acc3f3135f3ceeb</code></h3>"},"metadata":{}},{"name":"stdout","text":"Recent purchases:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                  prod_name product_type_name  product_group_name  \\\n0  Jen Bermuda denim shorts            Shorts  Garment Lower body   \n1   HEAVEN shaping HW tight   Leggings/Tights  Garment Lower body   \n2        Norway hood jacket            Hoodie  Garment Upper body   \n\n  colour_group_name       department_name      section_name  \\\n0        Light Blue       Shorts & Skirts     Womens Casual   \n1         Dark Grey  Ladies Sport Bottoms  Ladies H&M Sport   \n2             Green     Ladies Sport Bras  Ladies H&M Sport   \n\n  garment_group_name                                        detail_desc  \n0             Shorts  5-pocket shorts in washed, stretch denim with ...  \n1       Jersey Fancy  High-waisted sports tights in fast-drying func...  \n2       Jersey Fancy  Fitted jacket in fast-drying functional fabric...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prod_name</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>colour_group_name</th>\n      <th>department_name</th>\n      <th>section_name</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jen Bermuda denim shorts</td>\n      <td>Shorts</td>\n      <td>Garment Lower body</td>\n      <td>Light Blue</td>\n      <td>Shorts &amp; Skirts</td>\n      <td>Womens Casual</td>\n      <td>Shorts</td>\n      <td>5-pocket shorts in washed, stretch denim with ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HEAVEN shaping HW tight</td>\n      <td>Leggings/Tights</td>\n      <td>Garment Lower body</td>\n      <td>Dark Grey</td>\n      <td>Ladies Sport Bottoms</td>\n      <td>Ladies H&amp;M Sport</td>\n      <td>Jersey Fancy</td>\n      <td>High-waisted sports tights in fast-drying func...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Norway hood jacket</td>\n      <td>Hoodie</td>\n      <td>Garment Upper body</td>\n      <td>Green</td>\n      <td>Ladies Sport Bras</td>\n      <td>Ladies H&amp;M Sport</td>\n      <td>Jersey Fancy</td>\n      <td>Fitted jacket in fast-drying functional fabric...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Top 7 GNN Recommendations for Customer: <code>005ab9cb5f4cfda446299f48d109c002cb5396a6646445d22acc3f3135f3ceeb</code></h3>"},"metadata":{}},{"name":"stdout","text":"Recommended items:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                   prod_name product_type_name  product_group_name  \\\n0             Pink HW barrel          Trousers  Garment Lower body   \n1      Snow chino TVP RW TVP          Trousers  Garment Lower body   \n2               ELVIS JOGGER          Trousers  Garment Lower body   \n3            CORAL LONG HOOD            Hoodie  Garment Upper body   \n4       Speedy conscious tee           T-shirt  Garment Upper body   \n5          Baraboom throw-on          Cardigan  Garment Upper body   \n6  Perrie Slim Mom Denim TRS          Trousers  Garment Lower body   \n\n  colour_group_name perceived_colour_master_name    department_name  \\\n0       Light Beige                        Beige            Trouser   \n1             Black                        Black            Trouser   \n2             Green                  Khaki green             Jersey   \n3       Light Beige                        White             Jersey   \n4        Light Pink                         Pink  Ladies Sport Bras   \n5             Black                        Black           Knitwear   \n6        Light Blue                         Blue           Trousers   \n\n                 section_name garment_group_name  \\\n0  Womens Everyday Collection           Trousers   \n1               Womens Casual           Trousers   \n2               Womens Casual       Jersey Fancy   \n3               Womens Casual       Jersey Fancy   \n4            Ladies H&M Sport       Jersey Fancy   \n5  Womens Everyday Collection           Knitwear   \n6          Divided Collection           Trousers   \n\n                                         detail_desc  similarity_score  \n0  5-pocket, ankle-length trousers in washed cott...            0.1325  \n1  Ankle-length chinos in a soft cotton weave wit...            0.1545  \n2  Joggers in sweatshirt fabric with an elasticat...            0.1271  \n3  Oversized top in sweatshirt fabric with flatlo...            0.1368  \n4  Straight-cut sports top in fast-drying mesh wi...            0.1470  \n5  Long cardigan in a soft, fine knit containing ...            0.1413  \n6  5-pocket, ankle-length jeans in washed, sturdy...            0.1846  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prod_name</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>colour_group_name</th>\n      <th>perceived_colour_master_name</th>\n      <th>department_name</th>\n      <th>section_name</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n      <th>similarity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pink HW barrel</td>\n      <td>Trousers</td>\n      <td>Garment Lower body</td>\n      <td>Light Beige</td>\n      <td>Beige</td>\n      <td>Trouser</td>\n      <td>Womens Everyday Collection</td>\n      <td>Trousers</td>\n      <td>5-pocket, ankle-length trousers in washed cott...</td>\n      <td>0.1325</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Snow chino TVP RW TVP</td>\n      <td>Trousers</td>\n      <td>Garment Lower body</td>\n      <td>Black</td>\n      <td>Black</td>\n      <td>Trouser</td>\n      <td>Womens Casual</td>\n      <td>Trousers</td>\n      <td>Ankle-length chinos in a soft cotton weave wit...</td>\n      <td>0.1545</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ELVIS JOGGER</td>\n      <td>Trousers</td>\n      <td>Garment Lower body</td>\n      <td>Green</td>\n      <td>Khaki green</td>\n      <td>Jersey</td>\n      <td>Womens Casual</td>\n      <td>Jersey Fancy</td>\n      <td>Joggers in sweatshirt fabric with an elasticat...</td>\n      <td>0.1271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CORAL LONG HOOD</td>\n      <td>Hoodie</td>\n      <td>Garment Upper body</td>\n      <td>Light Beige</td>\n      <td>White</td>\n      <td>Jersey</td>\n      <td>Womens Casual</td>\n      <td>Jersey Fancy</td>\n      <td>Oversized top in sweatshirt fabric with flatlo...</td>\n      <td>0.1368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Speedy conscious tee</td>\n      <td>T-shirt</td>\n      <td>Garment Upper body</td>\n      <td>Light Pink</td>\n      <td>Pink</td>\n      <td>Ladies Sport Bras</td>\n      <td>Ladies H&amp;M Sport</td>\n      <td>Jersey Fancy</td>\n      <td>Straight-cut sports top in fast-drying mesh wi...</td>\n      <td>0.1470</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Baraboom throw-on</td>\n      <td>Cardigan</td>\n      <td>Garment Upper body</td>\n      <td>Black</td>\n      <td>Black</td>\n      <td>Knitwear</td>\n      <td>Womens Everyday Collection</td>\n      <td>Knitwear</td>\n      <td>Long cardigan in a soft, fine knit containing ...</td>\n      <td>0.1413</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Perrie Slim Mom Denim TRS</td>\n      <td>Trousers</td>\n      <td>Garment Lower body</td>\n      <td>Light Blue</td>\n      <td>Blue</td>\n      <td>Trousers</td>\n      <td>Divided Collection</td>\n      <td>Trousers</td>\n      <td>5-pocket, ankle-length jeans in washed, sturdy...</td>\n      <td>0.1846</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from neo4j import GraphDatabase\n\n# --- First, you would need to load the graph structure into Neo4j ---\n# This is typically done with Cypher queries, e.g.:\n# UNWIND $customers as customer MERGE (c:Customer {id: customer.id})\n# UNWIND $articles as article MERGE (a:Article {id: article.id, name: article.name})\n# etc. for all nodes and relationships.\n\n# --- Then, update nodes with their learned embeddings ---\nuri = \"neo4j://localhost:7687\"\nuser = \"neo4j\"\npassword = \"your_password\"\ndriver = GraphDatabase.driver(uri, auth=(user, password))\n\ndef store_embeddings(tx, node_label, embeddings, mapping):\n    # Convert PyTorch tensor to a list of lists\n    embeddings_list = embeddings.cpu().numpy().tolist()\n    # Create a reverse mapping from index to original ID\n    rev_mapping = {v: k for k, v in mapping.items()}\n    \n    for i, emb in enumerate(embeddings_list):\n        original_id = rev_mapping[i]\n        query = (\n            f\"MATCH (n:{node_label} {{id: $id}}) \"\n            \"SET n.embedding = $embedding\"\n        )\n        tx.run(query, id=original_id, embedding=emb)\n\nwith driver.session() as session:\n    session.write_transaction(store_embeddings, \"Customer\", customer_embeddings, customer_mapping)\n    session.write_transaction(store_embeddings, \"Article\", article_embeddings, article_mapping)\n    \ndriver.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}